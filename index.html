<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Hubble Suite">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hubble Suite</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”­</text></svg>">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://aflah02.github.io/TokenSmith/" target="_blank" rel="noopener noreferrer">
            TokenSmith
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Hubble: a Model Suite to Advance the Study of LLM Memorization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://johntzwei.github.io/" target="_blank" rel="noopener noreferrer">Johnny Tian-Zheng Wei*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ameyagodbole.github.io/" target="_blank" rel="noopener noreferrer">Ameya Godbole*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://aflah02.github.io/" target="_blank" rel="noopener noreferrer">Mohammad Aflah Khan*</a><sup>2</sup>,
            </span>
            <br />
            <span class="author-block">
              <a href="https://ryanyxw.github.io/" target="_blank" rel="noopener noreferrer">Ryan Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://xyzhu123.com/" target="_blank" rel="noopener noreferrer">Xiaoyuan Zhu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://james-flemings.github.io/" target="_blank" rel="noopener noreferrer">James Flemings</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/nitya-kashyap-bb119429a/" target="_blank" rel="noopener noreferrer">Nitya Kashyap</a><sup>1</sup>,
            </span>
            <br />
            <span class="author-block">
              <a href="https://people.mpi-sws.org/~gummadi/" target="_blank" rel="noopener noreferrer">Krishna P. Gummadi</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://willieneis.github.io/" target="_blank" rel="noopener noreferrer">Willie Neiswanger</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://robinjia.github.io/" target="_blank" rel="noopener noreferrer">Robin Jia</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Southern California,</span>
            <span class="author-block"><sup>2</sup>Max Planck Institute for Software Systems</span>
          </div>

          <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
            <span class="author-block">* indicates equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.19811"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/allegro-lab/hubble"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/allegrolab/hubble-core-68db785e0928a04885b0b7f6"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Models and Pretraining Datasets</span>
                  </a>
              </span>
              <!-- Perturbation Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/allegrolab/hubble-datasets"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
            <i class="fas fa-sliders-h"></i>
                  </span>
                  <span>Perturbation Data</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-centered">
          <p>
            We present HUBBLE, a suite of open-source large language models (LLMs) for the scientific study of LLM memorization. HUBBLE models come as minimal pairs: standard models are pretrained on a large English corpus, and perturbed models are trained in the same way but with controlled insertion of text (e.g., book passages, biographies, and test sets) designed to emulate key memorization risks. Our core release includes 8 modelsâ€”standard and perturbed, with 1B or 8B parameters, trained on 100B or 500B tokens. HUBBLEâ€™s core experiment establishes that memorization risks are determined by the frequency of sensitive data relative to the training corpus size (i.e., a password appearing once in a smaller corpus is memorized better than the same password in a larger corpus). Our release includes 6 more models with perturbations inserted at different pretraining phases; we observe perturbations without continued exposure can be forgotten. These findings suggest two best practices: to dilute sensitive data by increasing
            the training corpus size, and to order them to appear earlier in training. Beyond these general findings, HUBBLE enables a broad range of memorization research. We show that the randomized perturbations in HUBBLE make it an ideal testbed for membership inference and machine unlearning methods. We invite the community to explore, benchmark, and build upon our work.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<!-- Tabs for Experiment Results -->
<div class="section">
  <h2 class="title is-4 has-text-centered">Key Results</h2>

  <!-- Tab headers -->
  <div class="tabs is-centered is-boxed">
    <ul id="experiment-tabs">
      <li class="is-active" data-tab="exp1"><a>Dilution Effect</a></li>
      <li data-tab="exp2"><a>Effect of Injection Timing</a></li>
      <li data-tab="exp3"><a>Effect of Paraphrasing Injected Data</a></li>
      <li data-tab="exp4"><a>Evaluating MI Attacks</a></li>
      <li data-tab="exp5"><a>Evaluating Unlearning Methods</a></li>
    </ul>
  </div>

  <!-- Tab contents -->
  <div id="experiment-contents" class="has-text-centered">

    <!-- Experiment 1 -->
    <div class="tab-content is-hidden" id="exp1" style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images_static/dilution-hubble_8b-small_page_1.png"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>
      <!-- <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images/Slide_GIFs/slide_9.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images/Slide_GIFs/slide_10.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure> -->
      
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <p><b>Memorization of sensitive data can be diluted by training on larger corpora.</b><br> We report the base evaluations on a subset of tasks for the core 8B models trained on 100B and 500B tokens. For the same duplicate level, memorization is weaker for the model trained on 500B tokens compared to 100B.</p>
        </div>
      </div>
    </div>

    </div>

    <!-- Experiment 2 -->
  <div class="tab-content is-hidden" id="exp2">
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images_static/injectrange-main_page_1.png"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>
      
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <p><b>Sensitive data can be forgotten without continued exposure.</b><br>We report the performance of the Timing runs (1B models trained on 100B tokens) where perturbations are inserted in different phases of pretraining (tuples denote the range of pretraining where texts are inserted). For reference, the standard and perturbed 1B parameter models are also plotted.</p>
        </div>
      </div>
      </div>

      <!-- <figure class="has-text-centered">
        <img
          src="static/images/Slide_GIFs/slide_11.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure> -->
    </div>

    <!-- Experiment 3 -->
  <div class="tab-content is-hidden" id="exp3" style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images_static/paraphrase-full_page_1.png"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>

      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <p><b>Performance of Hubble perturbed models trained on paraphased insertions.</b><br>The models do not generalize from paraphrased examples seen in training to the original examples. However, PII can be reconstructed from models trained on paraphrased biographies, even with stronger attacks.</p>
        </div>
      </div>
      </div>
      
      <!-- <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images/Slide_GIFs/slide_12.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images/Slide_GIFs/slide_13.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure> -->
    </div>



    <!-- Experiment 4 -->
  <div class="tab-content is-hidden" id="exp4">
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images_static/eval_Gutenberg Unpopular_model_hubble-8b-500b_toks-perturbed-hf_page_1.png"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>

      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <p><b>ROC AUC scores of baseline MIAs for our largest perturbed model (8B, 500B tokens).</b><br> Dup indicates the duplication level of members. Dup > 0 treats all inserted perturbations as members. Non-members are always drawn from perturbations inserted 0 times. As duplication increases, memorization becomes stronger, and it becomes easier for membership inference attacks (MIA) to distinguish between members and non-members.</p>
        </div>
      </div>
      </div>

      
      <!-- <figure class="has-text-centered">
        <img
          src="static/images/Slide_GIFs/slide_16.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure> -->
    </div>

    <!-- Experiment 5 -->
  <div class="tab-content is-hidden" id="exp5">
      <figure class="has-text-centered" style="flex: 1 1 300px; text-align: center;">
        <img
          src="static/images_static/unlearn_main_page_1.png"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure>
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <p><b>Unlearning performance on Hubble 8B.</b><br>Three key reference points are included in each subplot: the perturbed model (red cross), representing performance before unlearning; the standard model (blue cross), which is trained without perturbations; and the desired model (yellow star), which achieves standard model's performance on the forget set while retaining the perturbed model's performance elsewhere. Improvement is indicated by the arrows. No unlearning method reaches the desired target and matches the performance of the standard model on the Unlearn set while retaining the other sets. Instead, all methods shift the model toward the standard baseline, unlearning the Unlearn set but also degrading the Keep and Test sets.</p>
        </div>
      </div>
      </div>
      
      <!-- <figure class="has-text-centered">
        <img
          src="static/images/Slide_GIFs/slide_17.gif"
          alt="Timing Experiment Results"
          style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"
        >
      </figure> -->
    </div>

  </div>
</div>

<script>
  // Simple tab toggle behavior with initial activation
  document.addEventListener('DOMContentLoaded', () => {
    const tabs = document.querySelectorAll('#experiment-tabs li');

    // Click handlers
    tabs.forEach(tab => {
      tab.addEventListener('click', () => {
        // Update active tab
        document.querySelectorAll('#experiment-tabs li').forEach(t => t.classList.remove('is-active'));
        tab.classList.add('is-active');

        // Show corresponding content
        const target = tab.dataset.tab;
        document.querySelectorAll('.tab-content').forEach(c => c.classList.add('is-hidden'));
        const content = document.getElementById(target);
        if (content) content.classList.remove('is-hidden');
      });
    });

    // Initial show: reveal the content of the tab marked as active (or the first tab)
    const active = document.querySelector('#experiment-tabs li.is-active') || tabs[0];
    if (active) {
      active.classList.add('is-active');
      const target = active.dataset.tab;
      document.querySelectorAll('.tab-content').forEach(c => c.classList.add('is-hidden'));
      const content = document.getElementById(target);
      if (content) content.classList.remove('is-hidden');
    }
  });
  
</script>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">

    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Artifacts</h2>

        <div class="content has-text-centered">
          <p>
            We release all our models, intermediate checkpoints, optimizer states and datasets to facilitate further research in LLM memorization.
          </p>
        </div>

        <!-- Resource cards -->
        <div class="columns is-multiline is-centered">
          <!-- Hubble Core (added at beginning) -->
          <div class="column is-full-mobile is-half-tablet is-one-quarter-desktop">
            <a class="resource-card-link" href="https://huggingface.co/collections/allegrolab/hubble-core-68db785e0928a04885b0b7f6" target="_blank" rel="noopener noreferrer">
              <div class="card resource-card">
                <div class="card-content has-text-centered">
                  <span class="icon is-large has-text-success"><i class="fas fa-database fa-2x" aria-hidden="true"></i></span>
                  <p class="title is-5" style="margin-top: 0.5rem;">Hubble Core</p>
                  <p class="is-size-6 has-text-grey">
                    Core models and datasets.
                  </p>
                  <span class="button is-link is-light is-small">View collection</span>
                </div>
              </div>
            </a>
          </div>
          <!-- Interference -->
          <div class="column is-full-mobile is-half-tablet is-one-quarter-desktop">
            <a class="resource-card-link" href="https://huggingface.co/collections/allegrolab/hubble-interference-68db77c4c886a804ae28c1f4" target="_blank" rel="noopener noreferrer">
              <div class="card resource-card">
                <div class="card-content has-text-centered">
                  <span class="icon is-large has-text-info"><i class="fas fa-random fa-2x" aria-hidden="true"></i></span>
                  <p class="title is-5" style="margin-top: 0.5rem;">Interference Experiments</p>
                  <p class="is-size-6 has-text-grey">
                    Study how inserted passages interact and interfere during training and recall.
                  </p>
                  <span class="button is-link is-light is-small">View collection</span>
                </div>
              </div>
            </a>
          </div>

          <!-- Timing -->
          <div class="column is-full-mobile is-half-tablet is-one-quarter-desktop">
            <a class="resource-card-link" href="https://huggingface.co/collections/allegrolab/hubble-timing-68db76f43001bfc806172ee5" target="_blank" rel="noopener noreferrer">
              <div class="card resource-card">
                <div class="card-content has-text-centered">
                  <span class="icon is-large has-text-warning"><i class="fas fa-clock fa-2x" aria-hidden="true"></i></span>
                  <p class="title is-5" style="margin-top: 0.5rem;">Timing Experiments</p>
                  <p class="is-size-6 has-text-grey">
                    Evaluate how the phase of injection affects long-term retention and forgetting.
                  </p>
                  <span class="button is-link is-light is-small">View collection</span>
                </div>
              </div>
            </a>
          </div>

          <!-- Paraphrase -->
          <div class="column is-full-mobile is-half-tablet is-one-quarter-desktop">
            <a class="resource-card-link" href="https://huggingface.co/collections/allegrolab/hubble-paraphrase-68db75ee6359ae9196b6a110" target="_blank" rel="noopener noreferrer">
              <div class="card resource-card">
                <div class="card-content has-text-centered">
                  <span class="icon is-large has-text-primary"><i class="fas fa-quote-right fa-2x" aria-hidden="true"></i></span>
                  <p class="title is-5" style="margin-top: 0.5rem;">Paraphrase Experiments</p>
                  <p class="is-size-6 has-text-grey">
                    Analyze robustness of memorization under paraphrasing and textual variation.
                  </p>
                  <span class="button is-link is-light is-small">View collection</span>
                </div>
              </div>
            </a>
          </div>

          <!-- Architecture -->
          <div class="column is-full-mobile is-half-tablet is-one-quarter-desktop">
            <a class="resource-card-link" href="https://huggingface.co/collections/allegrolab/hubble-architecture-68db747ecccdb8a9f8e53c5d" target="_blank" rel="noopener noreferrer">
              <div class="card resource-card">
                <div class="card-content has-text-centered">
                  <span class="icon is-large has-text-danger"><i class="fas fa-microchip fa-2x" aria-hidden="true"></i></span>
                  <p class="title is-5" style="margin-top: 0.5rem;">Architecture Experiments</p>
                  <p class="is-size-6 has-text-grey">
                    Compare model sizes and architectures to surface how design impacts memorization.
                  </p>
                  <span class="button is-link is-light is-small">View collection</span>
                </div>
              </div>
            </a>
          </div>

          <!-- Perturbation Data (added at end) -->
          <div class="column is-full-mobile is-half-tablet is-one-quarter-desktop">
            <a class="resource-card-link" href="https://huggingface.co/collections/allegrolab/hubble-datasets" target="_blank" rel="noopener noreferrer">
              <div class="card resource-card">
                <div class="card-content has-text-centered">
                  <span class="icon is-large has-text-link"><i class="fas fa-sliders-h fa-2x" aria-hidden="true"></i></span>
                  <p class="title is-5" style="margin-top: 0.5rem;">Perturbation Data</p>
                  <p class="is-size-6 has-text-grey">
                    Collections of injected passages across tasks and settings.
                  </p>
                  <span class="button is-link is-light is-small">View collection</span>
                </div>
              </div>
            </a>
          </div>
        </div>
        <!--/ Resource cards -->
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{wei2025hubblemodelsuiteadvance,
      title={Hubble: a Model Suite to Advance the Study of LLM Memorization}, 
      author={Johnny Tian-Zheng Wei and Ameya Godbole and Mohammad Aflah Khan and Ryan Wang and Xiaoyuan Zhu and James Flemings and Nitya Kashyap and Krishna P. Gummadi and Willie Neiswanger and Robin Jia},
      year={2025},
      eprint={2510.19811},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2510.19811}, 
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf" target="_blank" rel="noopener noreferrer">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link external-link" href="https://github.com/keunhong" target="_blank" rel="noopener noreferrer" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license noopener noreferrer"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io" target="_blank" rel="noopener noreferrer">source code</a> of this website,
            we just ask that you link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
